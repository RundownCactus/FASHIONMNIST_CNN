{"cells":[{"metadata":{},"cell_type":"markdown","source":"**|| I170282 || MUHAMMAD SALMAN QURESHI || DL ASSIGNMENT # 2 ||**"},{"metadata":{"_uuid":"a4834e4b-8a72-4f0f-9f41-941bb5463337","_cell_guid":"f4fee127-dc0f-45cd-a121-37eeb5b86f31","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"91431a1a-ae87-4f52-a704-0e1a837227b8","_cell_guid":"4c8d60df-e0c0-4e43-b9ac-2d58d66eb889","trusted":true},"cell_type":"code","source":"from subprocess import check_output\nimport pandas as pd\nimport numpy as np\nimport tensorflow\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import BatchNormalization\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7308d773-267f-48c8-916e-e874a1fa3d7a","_cell_guid":"1e770f7c-9790-4683-8dd8-f1b2714166ce","trusted":true},"cell_type":"code","source":"\ntrain_df = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_train.csv',sep=',')\ntest_df = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_test.csv', sep = ',')\n\ntrain_data = np.array(train_df, dtype = 'float32')\ntest_data = np.array(test_df,dtype='float32')\n\n\nx_train = train_data[:,1:]/255\ny_train = train_data[:,0]\nx_test = test_data[:,1:]/255\ny_test = test_data[:,0]\n\n\n# Reshape into one hot encoded vector\nx_train = x_train.reshape(x_train.shape[0], 28, 28,1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28,1)\n\n\n# One-hot encode the labels\ny_train = tensorflow.keras.utils.to_categorical(y_train, 10)\ny_test = tensorflow.keras.utils.to_categorical(y_test, 10)\n\n\n# Splitting Into Valid Set\n(x_train, x_valid) = x_train[5000:], x_train[:5000]\n(y_train, y_valid) = y_train[5000:], y_train[:5000]\n\n\nprint(x_train.shape,y_train.shape,y_test.shape)\nprint(x_valid.shape,y_valid.shape)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"68d17fe0-bb08-4627-b36d-72e783f2705a","_cell_guid":"81ad9703-8d9d-4ec5-b5b3-97ae9231045d","trusted":true},"cell_type":"code","source":"# Define the model\nmodel = Sequential()\npadding = ([[0,0],[1,1],[1,1],[0,0]])\n\nmodel.add(Conv2D(filters=64, kernel_size=3, activation='relu', kernel_initializer='he_normal', input_shape=(28,28,1))) \nmodel.add(MaxPooling2D(pool_size=2,strides=(1,1),padding = 'same'))\n\nmodel.add(Conv2D(filters=128, kernel_size=3,kernel_initializer='he_normal', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2,strides=(1,1),padding = 'same'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(filters=256, kernel_size=3, activation='relu', kernel_initializer='he_uniform')) \nmodel.add(Conv2D(filters=256, kernel_size=3, activation='relu', kernel_initializer='glorot_normal')) \n\nmodel.add(MaxPooling2D(pool_size=2,strides=(1,1),padding = 'same'))\nmodel.add(Flatten())\n\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(10, activation='softmax'))\n\n# Print the model summary\nmodel.summary()\n\n# Compile the model\nmodel.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\n# Training of the model\npatience = tensorflow.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\ncheckpointer = ModelCheckpoint(filepath='model_best_weights.hdf5', verbose = 1, save_best_only=True)\nhistory = model.fit(x_train,\n         y_train,\n         batch_size=32,\n         epochs=30,\n         validation_data=(x_valid, y_valid),\n         callbacks=[checkpointer,patience])\n\n","execution_count":7,"outputs":[{"output_type":"stream","text":"Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_12 (Conv2D)           (None, 26, 26, 64)        640       \n_________________________________________________________________\nmax_pooling2d_9 (MaxPooling2 (None, 26, 26, 64)        0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 24, 24, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_10 (MaxPooling (None, 24, 24, 128)       0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 24, 24, 128)       0         \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 22, 22, 256)       295168    \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 20, 20, 256)       590080    \n_________________________________________________________________\nmax_pooling2d_11 (MaxPooling (None, 20, 20, 256)       0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 102400)            0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 1024)              104858624 \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 1024)              1049600   \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 1024)              4096      \n_________________________________________________________________\ndense_11 (Dense)             (None, 10)                10250     \n=================================================================\nTotal params: 106,882,314\nTrainable params: 106,880,266\nNon-trainable params: 2,048\n_________________________________________________________________\nEpoch 1/30\n1717/1719 [============================>.] - ETA: 0s - loss: 0.6793 - accuracy: 0.7547\nEpoch 00001: val_loss improved from inf to 0.48625, saving model to model_best_weights.hdf5\n1719/1719 [==============================] - 34s 20ms/step - loss: 0.6791 - accuracy: 0.7548 - val_loss: 0.4862 - val_accuracy: 0.8048\nEpoch 2/30\n1719/1719 [==============================] - ETA: 0s - loss: 0.3927 - accuracy: 0.8574\nEpoch 00002: val_loss improved from 0.48625 to 0.34327, saving model to model_best_weights.hdf5\n1719/1719 [==============================] - 33s 19ms/step - loss: 0.3927 - accuracy: 0.8574 - val_loss: 0.3433 - val_accuracy: 0.8774\nEpoch 3/30\n1718/1719 [============================>.] - ETA: 0s - loss: 0.3248 - accuracy: 0.8824\nEpoch 00003: val_loss improved from 0.34327 to 0.27521, saving model to model_best_weights.hdf5\n1719/1719 [==============================] - 33s 19ms/step - loss: 0.3248 - accuracy: 0.8824 - val_loss: 0.2752 - val_accuracy: 0.8982\nEpoch 4/30\n1717/1719 [============================>.] - ETA: 0s - loss: 0.2875 - accuracy: 0.8951\nEpoch 00004: val_loss improved from 0.27521 to 0.24632, saving model to model_best_weights.hdf5\n1719/1719 [==============================] - 34s 20ms/step - loss: 0.2873 - accuracy: 0.8952 - val_loss: 0.2463 - val_accuracy: 0.9082\nEpoch 5/30\n1717/1719 [============================>.] - ETA: 0s - loss: 0.2564 - accuracy: 0.9047\nEpoch 00005: val_loss did not improve from 0.24632\n1719/1719 [==============================] - 32s 18ms/step - loss: 0.2564 - accuracy: 0.9047 - val_loss: 0.2595 - val_accuracy: 0.9012\nEpoch 6/30\n1719/1719 [==============================] - ETA: 0s - loss: 0.2376 - accuracy: 0.9131\nEpoch 00006: val_loss improved from 0.24632 to 0.22264, saving model to model_best_weights.hdf5\n1719/1719 [==============================] - 33s 19ms/step - loss: 0.2376 - accuracy: 0.9131 - val_loss: 0.2226 - val_accuracy: 0.9176\nEpoch 7/30\n1719/1719 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.9194\nEpoch 00007: val_loss improved from 0.22264 to 0.22060, saving model to model_best_weights.hdf5\n1719/1719 [==============================] - 33s 19ms/step - loss: 0.2185 - accuracy: 0.9194 - val_loss: 0.2206 - val_accuracy: 0.9214\nEpoch 8/30\n1718/1719 [============================>.] - ETA: 0s - loss: 0.1988 - accuracy: 0.9269\nEpoch 00008: val_loss improved from 0.22060 to 0.21494, saving model to model_best_weights.hdf5\n1719/1719 [==============================] - 33s 19ms/step - loss: 0.1987 - accuracy: 0.9269 - val_loss: 0.2149 - val_accuracy: 0.9236\nEpoch 9/30\n1719/1719 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.9330\nEpoch 00009: val_loss did not improve from 0.21494\n1719/1719 [==============================] - 32s 18ms/step - loss: 0.1807 - accuracy: 0.9330 - val_loss: 0.2184 - val_accuracy: 0.9274\nEpoch 10/30\n1719/1719 [==============================] - ETA: 0s - loss: 0.1667 - accuracy: 0.9382\nEpoch 00010: val_loss did not improve from 0.21494\n1719/1719 [==============================] - 32s 18ms/step - loss: 0.1667 - accuracy: 0.9382 - val_loss: 0.2197 - val_accuracy: 0.9228\nEpoch 11/30\n1717/1719 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.9429\nEpoch 00011: val_loss improved from 0.21494 to 0.20606, saving model to model_best_weights.hdf5\n1719/1719 [==============================] - 32s 19ms/step - loss: 0.1549 - accuracy: 0.9429 - val_loss: 0.2061 - val_accuracy: 0.9270\nEpoch 12/30\n1716/1719 [============================>.] - ETA: 0s - loss: 0.1418 - accuracy: 0.9467\nEpoch 00012: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 32s 18ms/step - loss: 0.1419 - accuracy: 0.9466 - val_loss: 0.2145 - val_accuracy: 0.9270\nEpoch 13/30\n1717/1719 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9518\nEpoch 00013: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 31s 18ms/step - loss: 0.1285 - accuracy: 0.9518 - val_loss: 0.2352 - val_accuracy: 0.9296\nEpoch 14/30\n1718/1719 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.9589\nEpoch 00014: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 32s 18ms/step - loss: 0.1150 - accuracy: 0.9589 - val_loss: 0.2351 - val_accuracy: 0.9260\nEpoch 15/30\n1719/1719 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9622\nEpoch 00015: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 31s 18ms/step - loss: 0.1035 - accuracy: 0.9622 - val_loss: 0.2241 - val_accuracy: 0.9304\nEpoch 16/30\n1718/1719 [============================>.] - ETA: 0s - loss: 0.0905 - accuracy: 0.9670\nEpoch 00016: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 31s 18ms/step - loss: 0.0906 - accuracy: 0.9670 - val_loss: 0.2360 - val_accuracy: 0.9362\nEpoch 17/30\n1718/1719 [============================>.] - ETA: 0s - loss: 0.0852 - accuracy: 0.9685\nEpoch 00017: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 32s 18ms/step - loss: 0.0852 - accuracy: 0.9685 - val_loss: 0.2370 - val_accuracy: 0.9330\nEpoch 18/30\n1718/1719 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 0.9720\nEpoch 00018: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 31s 18ms/step - loss: 0.0782 - accuracy: 0.9720 - val_loss: 0.2423 - val_accuracy: 0.9328\nEpoch 19/30\n1719/1719 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9745\nEpoch 00019: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 32s 18ms/step - loss: 0.0708 - accuracy: 0.9745 - val_loss: 0.2496 - val_accuracy: 0.9316\nEpoch 20/30\n1718/1719 [============================>.] - ETA: 0s - loss: 0.0632 - accuracy: 0.9774\nEpoch 00020: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 31s 18ms/step - loss: 0.0632 - accuracy: 0.9774 - val_loss: 0.2664 - val_accuracy: 0.9310\n","name":"stdout"},{"output_type":"stream","text":"Epoch 21/30\n1717/1719 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 0.9795\nEpoch 00021: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 32s 18ms/step - loss: 0.0559 - accuracy: 0.9795 - val_loss: 0.2588 - val_accuracy: 0.9330\nEpoch 22/30\n1719/1719 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9811\nEpoch 00022: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 31s 18ms/step - loss: 0.0515 - accuracy: 0.9811 - val_loss: 0.2637 - val_accuracy: 0.9372\nEpoch 23/30\n1719/1719 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9841\nEpoch 00023: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 31s 18ms/step - loss: 0.0453 - accuracy: 0.9841 - val_loss: 0.2689 - val_accuracy: 0.9340\nEpoch 24/30\n1718/1719 [============================>.] - ETA: 0s - loss: 0.0412 - accuracy: 0.9852\nEpoch 00024: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 31s 18ms/step - loss: 0.0413 - accuracy: 0.9852 - val_loss: 0.2885 - val_accuracy: 0.9350\nEpoch 25/30\n1717/1719 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9858\nEpoch 00025: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 31s 18ms/step - loss: 0.0410 - accuracy: 0.9858 - val_loss: 0.2960 - val_accuracy: 0.9246\nEpoch 26/30\n1717/1719 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9873\nEpoch 00026: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 31s 18ms/step - loss: 0.0350 - accuracy: 0.9873 - val_loss: 0.3017 - val_accuracy: 0.9368\nEpoch 27/30\n1717/1719 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9893\nEpoch 00027: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 32s 18ms/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 0.3013 - val_accuracy: 0.9350\nEpoch 28/30\n1719/1719 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9898\nEpoch 00028: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 31s 18ms/step - loss: 0.0288 - accuracy: 0.9898 - val_loss: 0.3148 - val_accuracy: 0.9336\nEpoch 29/30\n1717/1719 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9908\nEpoch 00029: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 32s 18ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.3139 - val_accuracy: 0.9298\nEpoch 30/30\n1717/1719 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9917\nEpoch 00030: val_loss did not improve from 0.20606\n1719/1719 [==============================] - 31s 18ms/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.3047 - val_accuracy: 0.9384\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}